knitr::opts_chunk$set(message=FALSE)
library(tidyverse)
library(tree)
library(caret)
library(randomForest)
library(gbm)
library(leaps)
library(MASS)
library(lmtest)
library(doParallel)
#Import the newsData csv file:
newsData <- read.csv(file="..//OnlineNewsPopularity//OnlineNewsPopularity.csv")
knitr::opts_chunk$set(echo=TRUE)
knitr::opts_chunk$set(warning=FALSE)
knitr::opts_chunk$set(message=FALSE)
library(tidyverse)
library(tree)
library(caret)
library(randomForest)
library(gbm)
library(leaps)
library(MASS)
library(lmtest)
library(doParallel)
#Import the newsData csv file:
newsData <- read.csv(file="E:/Statistics/ST558/project2/online+news+popularity/OnlineNewsPopularity/OnlineNewsPopularity.csv")
# Create single variable for data channel:
newsData <- newsData %>%
dplyr::select(-url, -timedelta) %>%
mutate(channel = ifelse(data_channel_is_lifestyle == 1, "Lifestyle",
ifelse(data_channel_is_entertainment == 1, "Entertainment",
ifelse(data_channel_is_bus == 1, "Business",
ifelse(data_channel_is_socmed == 1, "SocialMedia",
ifelse(data_channel_is_tech == 1, "Tech",
ifelse(data_channel_is_world == 1, "World", "Other")))))),
day_of_week = ifelse(weekday_is_monday == 1, "Monday",
ifelse(weekday_is_tuesday == 1, "Tuesday",
ifelse(weekday_is_wednesday == 1, "Wednesday",
ifelse(weekday_is_thursday == 1, "Thursday",
ifelse(weekday_is_friday == 1, "Friday",
ifelse(weekday_is_saturday == 1, "Saturday", "Sunday")))))),
content_length = ifelse(n_tokens_content <= 250, "Very Short",
ifelse(n_tokens_content <= 410, "Short",
ifelse(n_tokens_content <= 750, "Medium", "Long"))),
title_length = ifelse(n_tokens_title <= 8, "Short",
ifelse(n_tokens_title <= 12, "Medium",
ifelse(n_tokens_title <= 15, "Long","Very Long"))),
avg_positive_polarity_rate = ifelse(avg_positive_polarity <= 0.2, "Low",
ifelse(avg_positive_polarity <= 0.3, "Medium",
ifelse(avg_positive_polarity <= 0.4, "High","Very High")))
)
newsData$channel <- as.factor(newsData$channel) #Converting to factor
newsData$day_of_week <- factor(newsData$day_of_week,
levels = c("Sunday", "Monday", "Tuesday",
"Wednesday", "Thursday",
"Friday", "Saturday"))
newsData$content_length <- as.factor(newsData$content_length)
# Subset the data for each data channel
newsData_channel <- newsData %>% filter(channel == params$channel)
# Set the seed for reproducibility
set.seed(717)
# Create the training and test indices
trainIndices <- createDataPartition(newsData_channel$shares, p = 0.7, list = FALSE)
# Split the data into training and test sets
train_Data <- newsData_channel[trainIndices, ]
test_Data <- newsData_channel[-trainIndices, ]
summary(train_Data$shares)
# Histogram of shares
ggplot(train_Data , aes(x = shares)) +
geom_histogram(binwidth = 2500, fill = "blue") +
labs(x = "Shares", y = "Frequency") +
ggtitle("Distribution of Shares") +
theme_classic()
#Shares by day of the week
average_shares <- train_Data %>%
group_by(day_of_week) %>%
summarise(n = n(),
total_shares = sum(shares),
average_shares = mean(shares),
sd_shares = sd(shares),
min_shares = min(shares),
max_shares = max(shares))
average_shares
weekend_mean_shares <- train_Data %>%
group_by(is_weekend) %>%
rename(Weekend = is_weekend) %>%
mutate(Weekend = ifelse(Weekend == 0, "No", "Yes")) %>%
summarize(mean_shares = mean(shares))
weekend_mean_shares
ggplot(average_shares, aes(x = day_of_week, y = average_shares,
fill = day_of_week)) +
geom_col() +
labs(x = "Day of the Week", y = "Average Shares", fill = "Day of the Week") +
ggtitle("Average Shares by Day of the Week") +
theme_classic() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Calculate the average shares by content length category
average_shares_byContent <- train_Data %>%
group_by(content_length) %>%
summarise(n = n(),
average_shares = mean(shares),
sd_shares = sd(shares),
min_shares = min(shares),
max_shares = max(shares),
range_shares = max_shares - min_shares)
average_shares_byContent
# Create the horizontal bar chart
ggplot(average_shares_byContent, aes(x = average_shares, y = content_length, fill = content_length)) +
geom_bar(stat = "identity") +
labs(x = "Average Shares", y = "Content Length Category", fill = "Content Length") +
ggtitle("Average Shares by Content Length Category") +
theme_minimal() +
theme(axis.text.y = element_text(hjust = 0.5))
# Calculate the average shares by avg_positive_polarity_rate category
average_shares_byavg_positive_polarity_rate <- train_Data %>%
group_by(avg_positive_polarity_rate) %>%
summarise(n = n(),
average_shares = mean(shares),
sd_shares = sd(shares),
min_shares = min(shares),
max_shares = max(shares),
range_shares = max_shares - min_shares)
average_shares_byavg_positive_polarity_rate
# Create the horizontal bar chart
ggplot(average_shares_byavg_positive_polarity_rate, aes(x = avg_positive_polarity_rate, y = average_shares, fill = avg_positive_polarity_rate)) +
geom_bar(stat = "identity") +
labs(x = "avg_positive_polarity_rate Category", y = "Average Shares", fill = "avg_positive_polarity_rate") +
ggtitle("Average Shares by avg_positive_polarity_rate Category") +
theme_minimal() +
theme(axis.text.y = element_text(hjust = 0.6))
# Calculate the average shares by number of keywords
average_shares_bynum_keywords <- train_Data %>%
group_by(num_keywords) %>%
summarise(n = n(),
average_shares = mean(shares),
sd_shares = sd(shares),
min_shares = min(shares),
max_shares = max(shares),
range_shares = max_shares - min_shares)
average_shares_bynum_keywords
# Create the horizontal bar chart
ggplot(average_shares_bynum_keywords, aes(x = num_keywords, y = average_shares, fill = num_keywords)) +
geom_bar(stat = "identity") +
labs(x = "num_keywords", y = "Average Shares", fill = "num_keywords") +
ggtitle("Average Shares by number of keywords") +
theme_minimal() +
theme(axis.text.y = element_text(hjust = 0.5))
# Calculate the average shares by title length category
average_shares_byTitle <- train_Data %>%
group_by(title_length) %>%
summarise(n = n(),
average_shares = mean(shares),
sd_shares = sd(shares),
min_shares = min(shares),
max_shares = max(shares),
range_shares = max_shares - min_shares)
average_shares_byTitle
# Create the horizontal bar chart
ggplot(average_shares_byTitle, aes(x = title_length, y = average_shares, fill = title_length)) +
geom_bar(stat = "identity") +
labs(x = "Title Length Category", y = "Average Shares", fill = "Title Length") +
ggtitle("Average Shares by title Length Category") +
theme_minimal() +
theme(axis.text.y = element_text(hjust = 0.5))
# Calculate correlations between shares and all numeric variables
correlations <- cor(train_Data[, sapply(train_Data, is.numeric)],
train_Data$shares)
correlations
# subset the data:
train_Data_model <- dplyr::select(train_Data, shares, num_videos, n_tokens_content, n_tokens_title, num_imgs, num_hrefs, self_reference_min_shares, LDA_00, LDA_01, LDA_02, LDA_03, LDA_04, kw_avg_avg,day_of_week)
# all predictors from our subset:
lm_fit1 <- train(shares ~ . , data = train_Data_model,
method = "lm", preProcess = c("center", "scale"),
trControl = trainControl(method = "cv", number = 5))
# check the fit of our first linear model:
predslinear1 <- predict(lm_fit1, newdata = test_Data)
# See how well the model fits
postResample(predslinear1, obs = test_Data$shares)
# Parallel Processing
cores <- 10
cl <- makeCluster(cores)
registerDoParallel(cl)
step_model_seq <- train(shares ~ . , data = train_Data,
method = "leapSeq", preProcess = c("center", "scale"),
tuneGrid = data.frame(nvmax = 1:10), # up to 10 predictors max
trControl = trainControl(method = "cv", number = 5))
step_model_seq$results
step_model_seq$bestTune
# Stop parallel processing
stopCluster(cl)
registerDoSEQ()
predslinear2 <- predict(step_model_seq, newdata = test_Data)
# See how well the model fits
postResample(predslinear2, obs = test_Data$shares)
# Parallel Processing
cores <- 10
cl <- makeCluster(cores)
registerDoParallel(cl)
rfFit <- train(shares ~ ., data = train_Data_model, method = "rf",
trControl = trainControl(method = "cv", number = 5, repeats = 3),
preProcess = c("center", "scale"),
tuneGrid = data.frame(mtry = c(1:10)))
# Stop parallel processing
stopCluster(cl)
registerDoSEQ()
#review results:
rfFit$results
rfFit$bestTune
# Make predictions with random forest model
predsRf <- predict(rfFit, newdata = test_Data)
# Check model fit diagnostics
postResample(predsRf, obs = test_Data$shares)
boosted_grid <- expand.grid(n.trees = c(25, 50, 100, 150, 200),
interaction.depth = c(1, 2, 3, 4),
shrinkage = 0.1,
n.minobsinnode = 10)
num_cores <- detectCores()-1
# Set up parallel processing
cl <- makeCluster(num_cores)
registerDoParallel(cl)
boosted_model <- train(shares ~ ., data = train_Data,
method = "gbm",
trControl = trainControl(method = "repeatedcv",
number = 5, repeats = 3),
tuneGrid = boosted_grid,
#suppress output
verbose = FALSE )
# Stop parallel processing
stopCluster(cl)
registerDoSEQ()
# Make predictions with Boosted tree model
predsBf <- predict(boosted_model, newdata = test_Data)
# Check model fit diagnostics
postResample(predsBf, obs = test_Data$shares)
# Determine the best model
find_best <- function(lm1, lm2, rf, boost){
# Put all model results in a data frame
results <- data.frame(rbind("Linear Model 1"= postResample(predslinear1, test_Data$shares),
"Linear Model 2"= postResample(predslinear2, test_Data$shares),
"Random Forest"= postResample(predsRf, test_Data$shares),
"Boosted Tree" = postResample(predsBf, test_Data$shares)))
# Determine the name of the model with the lowest RMSE
model_winner <- row.names(results)[results$RMSE == min(results$RMSE)]
# Return both the data frame of results, as well as the row name of best model name in a list
return(list(results, model_winner))
}
# use our custom function to return the results of the best model and its name
best_model <- find_best(predslinear1, predslinear2, predsRf, predsBf)
# Print out the data frame of RMSE, Rsquared, and MAE
best_model[[1]]
# Print out a message that tells us which model is the best based on lowest RMSE
print(paste("The best model by finding the lowest RMSE on the test data is the", best_model[[2]], "model."))
library(tidyverse)
library(ggplot2)
scoreData <- read_csv(file = "E:/Statistics/ST558/project 3/effects-of-covid-19-on-trade-at-15-december-2021-provisional.csv")
# Histogram of shares
ggplot(scoreData , aes(x = Weekday)) +
geom_histogram(binwidth = 2500, fill = "blue") +
labs(x = "Weekday", y = "Value") +
ggtitle("Distribution of Shares")
library(tidyverse)
library(ggplot2)
scoreData <- read_csv(file = "E:/Statistics/ST558/project 3/effects-of-covid-19-on-trade-at-15-december-2021-provisional.csv")
g <- ggplot(data = scoreData, aes(x = Transport_Mode, y = Cumulative))
g + geom_point()
library(tidyverse)
library(ggplot2)
scoreData <- read_csv(file = "E:/Statistics/ST558/project 3/effects-of-covid-19-on-trade-at-15-december-2021-provisional.csv")
g <- ggplot(data = scoreData, aes(x = Transport_Mode, y = Cumulative))
g + geom_histogram()
library(tidyverse)
library(ggplot2)
scoreData <- read_csv(file = "E:/Statistics/ST558/project 3/effects-of-covid-19-on-trade-at-15-december-2021-provisional.csv")
g <- ggplot(data = scoreData, aes(x = Transport_Mode, y = Cumulative))
g + geom_point()
library(tidyverse)
library(ggplot2)
scoreData <- read_csv(file = "E:/Statistics/ST558/project 3/effects-of-covid-19-on-trade-at-15-december-2021-provisional.csv")
g <- ggplot(data = scoreData, aes(x = Year, y = Value))
g + geom_point()
library(tidyverse)
library(ggplot2)
scoreData <- read_csv(file = "E:/Statistics/ST558/project 3/effects-of-covid-19-on-trade-at-15-december-2021-provisional.csv")
g <- ggplot(data = scoreData, aes(x = Year, y = Cumulative))
g + geom_point()
library(tidyverse)
library(ggplot2)
scoreData <- read_csv(file = "E:/Statistics/ST558/project 3/effects-of-covid-19-on-trade-at-15-december-2021-provisional.csv")
g <- ggplot(data = scoreData, aes(x = Direction, y = Cumulative))
g + geom_point()
library(tidyverse)
library(ggplot2)
scoreData <- read_csv(file = "E:/Statistics/ST558/project 3/effects-of-covid-19-on-trade-at-15-december-2021-provisional.csv")
g <- ggplot(data = scoreData, aes(x = Commodity, y = Cumulative))
g + geom_point()
library(tidyverse)
library(ggplot2)
scoreData <- read_csv(file = "E:/Statistics/ST558/project 3/effects-of-covid-19-on-trade-at-15-december-2021-provisional.csv")
g <- ggplot(data = scoreData, aes(x = Commodity, y = Cumulative))
g + geom_point()
runApp('E:/Statistics/ST558/project 3/try/try3/try3')
library(tidyverse)
library(ggplot2)
scoreData <- read_csv(file = "E:/Statistics/ST558/project 3/effects-of-covid-19-on-trade-at-15-december-2021-provisional.csv")
# Create single variable for data channel:
scoreData <- scoreData %>%
dplyr::select(-Date, -Measure) %>%
mutate(Weekday = ifelse(Monday == 1, "Monday",
ifelse(Tuesday == 1, "Tuesday",
ifelse(Wednesday == 1, "Wednesday",
ifelse(Thursday == 1, "Thursday",
ifelse(Friday == 1, "Friday",
ifelse(Saturday == 1, "Saturday", "Sunday")))))),
Direction = ifelse(Exports == 1, "Exports",
ifelse(Imports == 1, "Imports", "Reimports")),
Transport_Mode = ifelse(Air == 1, "Air",
ifelse(Sea == 1, "Sea", "All")),
Year = ifelse(2015 == 1, "2015",
ifelse(2016 == 1, "2016",
ifelse(2017 == 1, "2017",
ifelse(2018 == 1, "2018",
ifelse(2019 == 1, "2019",
ifelse(2020 == 1, "2020", "2021")))))),
)
library(tidyverse)
library(ggplot2)
scoreData <- read_csv(file = "E:/Statistics/ST558/project 3/effects-of-covid-19-on-trade-at-15-december-2021-provisional.csv")
# Create single variable for data channel:
scoreData <- scoreData %>%
dplyr::select(-Date, -Measure)
scoreData$Year <- as.factor(scoreData$Year) #Converting to factor
scoreData$Weekday <- factor(scoreData$Weekday,
levels = c("Sunday", "Monday", "Tuesday",
"Wednesday", "Thursday",
"Friday", "Saturday"))
scoreData$Transport_Mode <- as.factor(scoreData$Transport_Mode)
scoreData$Direction <- as.factor(scoreData$Direction)
# Histogram of shares
ggplot(scoreData , aes(x = Weekday)) +
geom_histogram(binwidth = 2500, fill = "blue") +
labs(x = "Weekday", y = "Value") +
ggtitle("Distribution of Shares")
library(tidyverse)
library(ggplot2)
scoreData <- read_csv(file = "E:/Statistics/ST558/project 3/effects-of-covid-19-on-trade-at-15-december-2021-provisional.csv")
# Create single variable for data channel:
scoreData <- scoreData %>%
dplyr::select(-Date, -Measure)
scoreData$Year <- as.factor(scoreData$Year) #Converting to factor
scoreData$Weekday <- factor(scoreData$Weekday,
levels = c("Sunday", "Monday", "Tuesday",
"Wednesday", "Thursday",
"Friday", "Saturday"))
scoreData$Transport_Mode <- as.factor(scoreData$Transport_Mode)
scoreData$Direction <- as.factor(scoreData$Direction)
# Histogram of shares
g <- ggplot(data = scoreData, aes(x = Transport_Mode, y = Cumulative))
g + geom_histogram()
library(tidyverse)
library(ggplot2)
scoreData <- read_csv(file = "E:/Statistics/ST558/project 3/effects-of-covid-19-on-trade-at-15-december-2021-provisional.csv")
library(dplyr)
aggregated_data <- scoreData %>%
group_by(Weekday) %>%
summarise(Total_Value = sum(Value))
# Plot the histogram
library(ggplot2)
ggplot(aggregated_data, aes(x = Weekday, y = Total_Value)) +
geom_bar(stat = "identity", fill = "blue") +
labs(title = "Total Value by Weekday", x = "Weekday", y = "Total Value")
library(tidyverse)
library(ggplot2)
scoreData <- read_csv(file = "E:/Statistics/ST558/project 3/effects-of-covid-19-on-trade-at-15-december-2021-provisional.csv")
library(dplyr)
aggregated_data <- scoreData %>%
group_by(Transport_Mode) %>%
summarise(Total_Value = sum(Value))
# Plot the histogram
library(ggplot2)
ggplot(aggregated_data, aes(x = Transport_Mode, y = Total_Value)) +
geom_bar(stat = "identity", fill = "blue") +
labs(title = "Total Value by Transport_Mode", x = "Transport_Mode", y = "Total Value")
library(tidyverse)
library(ggplot2)
scoreData <- read_csv(file = "E:/Statistics/ST558/project 3/effects-of-covid-19-on-trade-at-15-december-2021-provisional.csv")
library(dplyr)
aggregated_data <- scoreData %>%
group_by(Year) %>%
summarise(Total_Value = sum(Value))
# Plot the histogram
library(ggplot2)
ggplot(aggregated_data, aes(x = Year, y = Total_Value)) +
geom_bar(stat = "identity", fill = "blue") +
labs(title = "Total Value by Year", x = "Year", y = "Total Value")
runApp('E:/Statistics/ST558/project 3/try/try3/try3')
library(tidyverse)
library(ggplot2)
scoreData <- read_csv(file = "E:/Statistics/ST558/project 3/effects-of-covid-19-on-trade-at-15-december-2021-provisional.csv")
library(dplyr)
aggregated_data <- scoreData %>%
group_by(Direction) %>%
summarise(Total_Value = sum(Value))
# Plot the histogram
library(ggplot2)
ggplot(aggregated_data, aes(x = Direction, y = Total_Value)) +
geom_bar(stat = "identity", fill = "blue") +
labs(title = "Total Value by Direction", x = "Direction", y = "Total Value")
library(tidyverse)
library(ggplot2)
scoreData <- read_csv(file = "E:/Statistics/ST558/project 3/effects-of-covid-19-on-trade-at-15-december-2021-provisional.csv")
library(dplyr)
aggregated_data <- scoreData %>%
group_by(Direction) %>%
summarise(Total_Value = sum(Value))
# Plot the histogram
library(ggplot2)
ggplot(aggregated_data, aes(x = Direction, y = Total_Value)) +
geom_bar(stat = "identity", fill = "blue") +
labs(title = "Total Value by Direction", x = "Direction", y = "Total Value")
library(tidyverse)
library(ggplot2)
scoreData <- read_csv(file = "E:/Statistics/ST558/project 3/effects-of-covid-19-on-trade-at-15-december-2021-provisional.csv")
library(dplyr)
aggregated_data <- scoreData %>%
group_by(Country) %>%
summarise(Total_Value = sum(Value))
# Plot the histogram
library(ggplot2)
ggplot(aggregated_data, aes(x = Country, y = Total_Value)) +
geom_bar(stat = "identity", fill = "blue") +
labs(title = "Total Value by Country", x = "Country", y = "Total Value")
library(tidyverse)
library(ggplot2)
scoreData <- read_csv(file = "E:/Statistics/ST558/project 3/effects-of-covid-19-on-trade-at-15-december-2021-provisional.csv")
library(dplyr)
aggregated_data <- scoreData %>%
group_by(Commodity) %>%
summarise(Total_Value = sum(Value))
# Plot the histogram
library(ggplot2)
ggplot(aggregated_data, aes(x = Commodity, y = Total_Value)) +
geom_bar(stat = "identity", fill = "blue") +
labs(title = "Total Value by Commodity", x = "Commodity", y = "Total Value")
library(tidyverse)
library(ggplot2)
tradedata <- read_csv(file = "E:/Statistics/ST558/project 3/effects-of-covid-19-on-trade-at-15-december-2021-provisional.csv")
# Convert "Region" into dummy variables using dummy coding (one-hot encoding)
data_dummies <- tradedata %>%
mutate(
Air = ifelse(Transport_Mode == "Air", 1, 0),
Sea = ifelse(Transport_Mode == "Sea", 1, 0),
All = ifelse(Transport_Mode == "All", 1, 0),
Exports = ifelse(Direction == "Exports", 1, 0),
Imports = ifelse(Direction == "Imports", 1, 0),
Reimports = ifelse(Direction == "Reimports", 1, 0),
)
# Fit multiple regression model with Sales as the response variable
lmFit1 <- train(Cumulative ~ Value + Air + Sea + All, data = data_dummies, method = "lm")
library(tidyverse)
library(ggplot2)
tradedata <- read_csv(file = "E:/Statistics/ST558/project 3/effects-of-covid-19-on-trade-at-15-december-2021-provisional.csv")
# Convert "Region" into dummy variables using dummy coding (one-hot encoding)
data_dummies <- tradedata %>%
mutate(
Air = ifelse(Transport_Mode == "Air", 1, 0),
Sea = ifelse(Transport_Mode == "Sea", 1, 0),
All = ifelse(Transport_Mode == "All", 1, 0),
Exports = ifelse(Direction == "Exports", 1, 0),
Imports = ifelse(Direction == "Imports", 1, 0),
Reimports = ifelse(Direction == "Reimports", 1, 0),
)
# Fit multiple regression model with Sales as the response variable
lmFit <- train(Cumulative ~ Value + Air + Sea + All, data = data_dummies, method = "lm")
library(tidyverse)
library(ggplot2)
library(caret)
tradedata <- read_csv(file = "E:/Statistics/ST558/project 3/effects-of-covid-19-on-trade-at-15-december-2021-provisional.csv")
# Convert "Region" into dummy variables using dummy coding (one-hot encoding)
data_dummies <- tradedata %>%
mutate(
Air = ifelse(Transport_Mode == "Air", 1, 0),
Sea = ifelse(Transport_Mode == "Sea", 1, 0),
All = ifelse(Transport_Mode == "All", 1, 0),
Exports = ifelse(Direction == "Exports", 1, 0),
Imports = ifelse(Direction == "Imports", 1, 0),
Reimports = ifelse(Direction == "Reimports", 1, 0),
)
# Fit multiple regression model with Sales as the response variable
lmFit <- train(Cumulative ~ Value + Air + Sea + All, data = data_dummies, method = "lm")
lmFit
shiny::runApp('E:/Statistics/ST558/project 3/try/try3/try3')
runApp('E:/Statistics/ST558/project 3/try/try3/try3')
runApp('E:/Statistics/ST558/project 3/try/try3/try3')
runApp('E:/Statistics/ST558/project 3/try/try3/try3')
runApp('E:/Statistics/ST558/project 3/try/try3/try3')
runApp('E:/Statistics/ST558/project 3/try/try3/try3')
runApp('E:/Statistics/ST558/project 3/try/try3/try3')
runApp('E:/Statistics/ST558/project 3/try/try3/try3')
runApp('E:/Statistics/ST558/project 3/try/try3/try3')
runApp('E:/Statistics/ST558/project 3/try/try3/try3')
shiny::runApp('E:/Statistics/ST558/project 3/try/try3/try3')
runApp('E:/Statistics/ST558/project 3/try/try3/try3')
runApp('E:/Statistics/ST558/project 3/try/try3/try3')
runApp('E:/Statistics/ST558/project 3/try/try3/try3')
runApp('E:/Statistics/ST558/project 3/try/try3/try3')
runApp('E:/Statistics/ST558/project 3/try/try3/try3')
runApp('E:/Statistics/ST558/project 3/try/try3/try3')
runApp('E:/Statistics/ST558/project 3/try/try3/try3')
runApp('E:/Statistics/ST558/project 3/try/try3/try3')
runApp('E:/Statistics/ST558/project 3/try/try3/try3')
runApp('E:/Statistics/ST558/project 3/try/try3/try3')
runApp('E:/Statistics/ST558/project 3/try/try3/try3')
